{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b0833e-116b-421a-9c7a-e4c162fdaa84",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center;\">Endoscope Semantic Segmentation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377cbb9-eac8-4d33-b29c-1efab39580b0",
   "metadata": {},
   "source": [
    "\n",
    "  <h2>Project Scope and Overview</h2>\n",
    "  <p>This project focuses on advancing semantic segmentation in medical imaging, particularly for computer-assisted surgery. The main objective is to develop neural network models that can accurately segment surgical images into distinct classes, such as various tissues, surgical instruments, blood vessels, and other critical anatomical structures. By improving segmentation accuracy, the project aims to enhance real-time surgical navigation and safety, providing essential support for clinical decision-making during operations.</p>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6747cd6-5773-4842-b39e-782f9b0bd252",
   "metadata": {},
   "source": [
    "<body>\n",
    "\n",
    "  <h2>Dataset Overview</h2>\n",
    "<p>\n",
    "  The CholecSeg8K dataset is organized into a clear hierarchical structure, making it easy to locate and use the data. Below is a breakdown of its organization:\n",
    "</p>\n",
    "<ul>\n",
    "  <li>\n",
    "    <strong>Top-Level Directories:</strong>\n",
    "    <ul>\n",
    "      <li>Folders are labeled as <em>video01</em>, <em>video02</em>, etc., where each folder represents a complete surgical video clip.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Segment Directories:</strong>\n",
    "    <ul>\n",
    "      <li>Within each video folder, the video is divided into several segments.</li>\n",
    "      <li>Each segment directory is named with the video ID and the starting frame number (for example, <em>video01_00080</em> indicates that the segment starts at frame 80).</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Frame and Image Files:</strong>\n",
    "    <ul>\n",
    "      <li>Each segment directory contains <strong>80 consecutive frames</strong> extracted from the video.</li>\n",
    "      <li>For every frame, there are <strong>4 image files</strong>:\n",
    "        <ul>\n",
    "          <li>The raw image frame</li>\n",
    "          <li>The annotation tool mask (the original hand-drawn annotation)</li>\n",
    "          <li>The color mask (used for visualization, where classes are painted in distinct colors)</li>\n",
    "          <li>The watershed mask (used for processing, where each pixel value corresponds to a class ID)</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>This results in <strong>80 frames × 4 images per frame = 320 images</strong> in each segment directory.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Annotations:</strong>\n",
    "    <ul>\n",
    "      <li>Each frame is annotated at the pixel level for 13 distinct classes (e.g., tissue, instruments, blood vessels, etc.).</li>\n",
    "      <li>The annotations are presented in both the color and watershed masks, ensuring clear class identification for both visualization and automated processing.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "<p>\n",
    "  This structured, high-quality organization facilitates the development and training of advanced neural networks for precise semantic segmentation in surgical environments.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfb569-7174-417f-a7a9-eb823aa4c770",
   "metadata": {},
   "source": [
    "<body>\n",
    "  <div class=\"gallery\">\n",
    "    <img src=\"./Images/Fig1.png\" alt=\"Figure 1\">\n",
    "    <img src=\"./Images/Fig2.png\" alt=\"Figure 2\">\n",
    "    <img src=\"./Images/Fig3.png\" alt=\"Figure 3\">\n",
    "  </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97e5b8-58f5-4829-a28c-83df4af1dc00",
   "metadata": {},
   "source": [
    "\n",
    "  <h2>Class Information Table</h2>\n",
    "  <p>Table I shows the corresponding class names of the class numbers in Figure 1, 2, 3 and the RGB hex code in the watershed masks:</p>\n",
    "  <table>\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th>Class Number</th>\n",
    "        <th>Class Name</th>\n",
    "        <th>RGB Hexcode</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <td>Class 0</td>\n",
    "        <td>Black Background</td>\n",
    "        <td>#505050</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 1</td>\n",
    "        <td>Abdominal Wall</td>\n",
    "        <td>#111111</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 2</td>\n",
    "        <td>Liver</td>\n",
    "        <td>#212121</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 3</td>\n",
    "        <td>Gastrointestinal Tract</td>\n",
    "        <td>#131313</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 4</td>\n",
    "        <td>Fat</td>\n",
    "        <td>#121212</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 5</td>\n",
    "        <td>Grasper</td>\n",
    "        <td>#313131</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 6</td>\n",
    "        <td>Connective Tissue</td>\n",
    "        <td>#232323</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 7</td>\n",
    "        <td>Blood</td>\n",
    "        <td>#242424</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 8</td>\n",
    "        <td>Cystic Duct</td>\n",
    "        <td>#252525</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 9</td>\n",
    "        <td>L-hook Electrocautery</td>\n",
    "        <td>#323232</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 10</td>\n",
    "        <td>Gallbladder</td>\n",
    "        <td>#222222</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 11</td>\n",
    "        <td>Hepatic Vein</td>\n",
    "        <td>#333333</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Class 12</td>\n",
    "        <td>Liver Ligament</td>\n",
    "        <td>#050505</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f39d5f-5a33-4e0c-869d-e29b3e6ca0b3",
   "metadata": {},
   "source": [
    "<h2>Mask Overview</h2>\n",
    "<p>\n",
    "  The table below summarizes the three types of masks that accompany each image frame, along with their descriptions and corresponding images.\n",
    "</p>\n",
    "<table border=\"1\" cellspacing=\"0\" cellpadding=\"10\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Mask Name</th>\n",
    "      <th>Description</th>\n",
    "      <th>Image</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Original Image Frame</td>\n",
    "      <td>This is the raw endoscopic image captured during the surgery.</td>\n",
    "      <td><img src=\"./Images/frame_100_endo.png\" alt=\"Original Endoscopic Image\" width=\"200\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1. Annotation Tool Mask</td>\n",
    "      <td>\n",
    "        <ul>\n",
    "          <li>This is the original hand-drawn mask created during the annotation process.</li>\n",
    "          <li>It contains detailed pixel-level annotations drawn by experts.</li>\n",
    "          <li>It serves as the basis for generating the other two masks.</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "      <td><img src=\"./Images/frame_100_endo_mask.png\" alt=\"Annotation Tool Mask\" width=\"200\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2. Color Mask</td>\n",
    "      <td>\n",
    "        <ul>\n",
    "          <li>Derived from the annotation tool mask.</li>\n",
    "          <li>It assigns a unique color to each class (e.g., tissue, instrument, blood vessel) based on predefined IDs.</li>\n",
    "          <li>This facilitates visual inspection and interpretation of the segmentation results.</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "      <td><img src=\"./Images/frame_100_endo_color_mask.png\" alt=\"Color Mask\" width=\"200\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3. Watershed Mask</td>\n",
    "      <td>\n",
    "        <ul>\n",
    "          <li>Also generated from the annotation tool mask.</li>\n",
    "          <li>It assigns a uniform pixel value (the same across all three RGB channels) to each class.</li>\n",
    "          <li>These numerical values represent the class IDs, making it ideal for automated processing and further analysis.</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "      <td><img src=\"./Images/frame_100_endo_watershed_mask.png\" alt=\"Watershed Mask\" width=\"200\"></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5fb56e-8694-4e7e-aa2f-47cad3166e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362f6258-1257-4604-b45e-6e672dae64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26241dd-0b1a-4df1-a402-f141f94d0988",
   "metadata": {},
   "source": [
    "<h2>I. Data Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf939c1-c7ed-4125-b908-4d06424d2051",
   "metadata": {},
   "source": [
    "<h3>a. Dataset Loading and Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3861b-160b-4dc6-a745-d7fbdf7325ed",
   "metadata": {},
   "source": [
    "```\n",
    "Dataset/\n",
    "│\n",
    "├── video01/\n",
    "│   ├── video01_00000/\n",
    "│   │   ├── frame00000_endo.png                  ← Raw image (input)\n",
    "│   │   ├── frame00000_endo_annotation.png       ← Annotation tool mask\n",
    "│   │   ├── frame00000_endo_color_mask.png       ← Color mask (visualization)\n",
    "│   │   ├── frame00000_endo_watershed_mask.png   ← Watershed mask (labels)\n",
    "│   │   ├── frame00001_endo.png\n",
    "│   │   ├── ...\n",
    "│   │   └── frame00079_endo_watershed_mask.png\n",
    "│   ├── video01_00080/\n",
    "│   │   ├── frame00080_endo.png\n",
    "│   │   ├── ...\n",
    "│\n",
    "├── video02/\n",
    "│   ├── video02_00000/\n",
    "│   │   ├── frame00000_endo.png\n",
    "│   │   └── ...\n",
    "│\n",
    "├── ...\n",
    "│\n",
    "└── video17/\n",
    "    └── ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d660419-5048-42f7-bca8-2847a2d75b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect the Dataset directory relative to the notebook's location\n",
    "dataset_dir = os.path.join(os.getcwd(), \"Dataset\")\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    raise FileNotFoundError(f\"Dataset folder not found at: {dataset_dir}\\n\"\n",
    "                            f\"Please ensure the 'Dataset' folder is placed in the same directory as this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392cb85-6ec6-4fff-b768-fd64f9e5fcbe",
   "metadata": {},
   "source": [
    "Our data loading pipeline specifically targets two types of files:\n",
    "\n",
    "- **Original frames** — filenames containing `_endo.png` (without any suffix like `_mask` or `_annotation`).  \n",
    "  These are the raw RGB endoscopic images used as **inputs** to the model.\n",
    "\n",
    "- **Watershed masks** — filenames containing `_endo_watershed_mask.png`.  \n",
    "  These masks encode pixel-wise class IDs and are used as **ground truth labels** during training.\n",
    "\n",
    "We will gather all such image–mask pairs, ensuring that **each original image has a corresponding watershed mask** before including it in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6dc01-d23e-48bd-8261-7ddb1cd8ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect file paths for all images and their corresponding watershed masks\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for filename in files:\n",
    "        \n",
    "        # Identify original image frames (filenames end with \"_endo.png\" and are not masks)\n",
    "        if filename.endswith(\"_endo.png\") and \"mask\" not in filename:\n",
    "            \n",
    "            img_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Construct the corresponding watershed mask filename\n",
    "            mask_filename = filename.replace(\"_endo.png\", \"_endo_watershed_mask.png\")\n",
    "            mask_path = os.path.join(root, mask_filename)\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                image_paths.append(img_path)\n",
    "                mask_paths.append(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689aef7-d11e-4809-ab82-014feca3097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the paths for consistency\n",
    "image_paths.sort()\n",
    "mask_paths.sort()\n",
    "print(f\"Found {len(image_paths)} image-mask pairs.\")  # Expected: 8080 pairs for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dbaa5-ad85-436a-854a-ddf8151d478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare arrays for images and masks\n",
    "num_samples = len(image_paths)\n",
    "img_height, img_width = 256, 256\n",
    "\n",
    "X = np.zeros((num_samples, img_height, img_width, 3), dtype=np.float32)\n",
    "y = np.zeros((num_samples, img_height, img_width), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de477861-11bd-4e08-a18a-eca53b5477f7",
   "metadata": {},
   "source": [
    "- Each pixel in a watershed mask encodes a **semantic class** using a unique **grayscale intensity**.\n",
    "- The intensity is uniform across all three channels (R = G = B), making it easy to identify programmatically.\n",
    "- These grayscale values are **mapped to integer class IDs** ranging from 0 to 12.\n",
    "- This mapping is essential for training the model using pixel-wise classification.\n",
    "- In total, there are **13 distinct classes**, including the background and various anatomical structures relevant to laparoscopic surgery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa664ac9-5d0e-4678-968f-608a91e5193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping from grayscale values to class IDs (13 classes including background)\n",
    "value_to_class = {\n",
    "    80: 0,   # background (#505050)\n",
    "    17: 1,   # abdominal wall (#111111)\n",
    "    33: 2,   # liver (#212121)\n",
    "    19: 3,   # gastrointestinal tract (#131313)\n",
    "    18: 4,   # fat (#121212)\n",
    "    49: 5,   # grasper (instrument) (#313131)\n",
    "    35: 6,   # connective tissue (#232323)\n",
    "    36: 7,   # blood (#242424)\n",
    "    37: 8,   # cystic duct (#252525)\n",
    "    50: 9,   # L-hook electrocautery (instrument) (#323232)\n",
    "    34: 10,  # gallbladder (#222222)\n",
    "    51: 11,  # hepatic vein (#333333)\n",
    "    5: 12    # liver ligament (#050505)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1e04b-aa60-46f2-abdc-9245c48464ad",
   "metadata": {},
   "source": [
    "<p>\n",
    "Each image in the dataset is originally <strong>854×480 pixels</strong>. For training purposes, both the images and their corresponding masks are resized to <strong>256×256 pixels</strong>. This resizing is a common practice to reduce memory consumption and computational overhead, while still retaining enough detail for semantic segmentation. The chosen size of 256×256 provides a good trade-off between information preservation and model efficiency.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Image pixel values are <strong>normalized to the [0, 1] range</strong> by dividing by 255. This standardization helps the neural network train faster and more reliably by keeping inputs on a consistent scale. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Watershed masks are treated differently. Each pixel in the mask uses a uniform grayscale value across the R, G, and B channels (e.g., <code>[80, 80, 80]</code>). These grayscale values correspond to specific class labels. We convert each pixel to an integer class ID from <strong>0 to 12</strong> based on a predefined mapping. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "For example: <code>[80, 80, 80]</code> (hex <code>#505050</code>) represents class 0 (background), while <code>[33, 33, 33]</code> (hex <code>#212121</code>) represents class 2 (liver). This mapping is derived from the dataset documentation and ensures accurate labeling for training.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7dc5c-177d-46b2-9ebf-67816beb7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess each image and mask\n",
    "for i, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n",
    "    \n",
    "    # Load and resize the image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((img_width, img_height), Image.Resampling.BILINEAR)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # normalize\n",
    "    X[i] = img_array\n",
    "\n",
    "    # Load and resize the watershed mask\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    mask = mask.resize((img_width, img_height), Image.Resampling.NEAREST)\n",
    "    mask_array = np.array(mask, dtype=np.uint8)\n",
    "    \n",
    "    # Map grayscale pixel values to class IDs\n",
    "    mask_mapped = np.zeros_like(mask_array, dtype=np.uint8)\n",
    "    for val, cls in value_to_class.items():\n",
    "        mask_mapped[mask_array == val] = cls\n",
    "    y[i] = mask_mapped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eec34f-f0de-48d7-a66c-db36ac73064b",
   "metadata": {},
   "source": [
    "During preprocessing, each image–mask pair is resized to a fixed dimension of **256×256 pixels** using different interpolation strategies for the input image and its corresponding label mask:\n",
    "\n",
    "- **Image resizing:**\n",
    "  - Each RGB image is loaded and converted to a 3-channel format (`RGB`).\n",
    "  - It is then resized using **bilinear interpolation** (`Image.Resampling.BILINEAR`), which computes the output pixel value as a weighted average of the nearest four pixels. \n",
    "  - This method preserves smooth gradients and is suitable for natural images, making it ideal for input data to convolutional networks.\n",
    "  - After resizing, the image is normalized to the **[0, 1]** range by dividing by 255, ensuring consistent input scale for the neural network.\n",
    "\n",
    "- **Mask resizing:**\n",
    "  - Each watershed mask is loaded in **grayscale** mode (`\"L\"`), resulting in a single-channel image.\n",
    "  - It is resized using **nearest-neighbor interpolation** (`Image.Resampling.NEAREST`) to preserve **discrete class boundaries**. This avoids introducing interpolated pixel values that could distort class labels.\n",
    "  - The resized mask is then converted from grayscale pixel values to **class IDs** (0 to 12) using a predefined mapping, ensuring the model receives accurate training labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2293a04-d3bd-4a36-9174-fbf154f61e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8080 image-mask pairs.\n",
      "Data loaded successfully!\n",
      "Shape of X (images): (8080, 256, 256, 3)\n",
      "Shape of y (masks): (8080, 256, 256)\n",
      "Image pixel range [min, max]: 0.0 1.0\n",
      "Unique mask labels: [ 0  2  9 12]\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print(\"Data loaded successfully!\")\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of y (masks):\", y.shape)\n",
    "print(\"Image pixel range [min, max]:\", X.min(), X.max())\n",
    "print(\"Unique mask labels:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e8c17-e423-4d4f-ab2b-48f918eb0f6b",
   "metadata": {},
   "source": [
    "<h3>b. Data splitting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4ddf9-1412-4e04-8346-b5f1595690ad",
   "metadata": {},
   "source": [
    "To evaluate our model's performance on unseen data, we separate the dataset into:\n",
    "\n",
    "- **Training set (80%)**  \n",
    "  Used to train the neural network and update weights.\n",
    "\n",
    "- **Validation set (20%)**  \n",
    "  Used to monitor model performance on unseen data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577ba43a-30c0-4d20-a6c1-6b8a8c42ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6464 images\n",
      "Validation set size: 1616 images\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets (e.g., 80% train, 20% val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set size:\", X_train.shape[0], \"images\")\n",
    "print(\"Validation set size:\", X_val.shape[0], \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cefe86-9050-4850-99d3-7496bdd1132e",
   "metadata": {},
   "source": [
    "<h2>II. Model Architecture: U-Net for Semantic Segmentation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e8425-c0df-43a4-8b53-9dcb1c11ff03",
   "metadata": {},
   "source": [
    "<h3>a. Defining Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9075d-f2b6-4251-9616-604322ae7a05",
   "metadata": {},
   "source": [
    "For this project, we use a **U-Net architecture** — a popular encoder–decoder convolutional neural network designed for semantic segmentation tasks in biomedical imaging.\n",
    "\n",
    "U-Net is built to capture both **global context** and **fine-grained local details**, thanks to its **skip connections** that link the encoder and decoder paths.\n",
    "\n",
    "---\n",
    "\n",
    "#### Architecture Overview\n",
    "\n",
    "- **Encoder (Contracting Path):**\n",
    "  - Consists of **4 downsampling blocks**\n",
    "  - Each block includes:\n",
    "    - Two `3×3` convolutional layers with ReLU activation\n",
    "    - A `2×2` max pooling layer for spatial downsampling\n",
    "  - The number of filters doubles at each stage:  \n",
    "    `64 → 128 → 256 → 512`\n",
    "  - After the fourth block, there's a **bottleneck layer** with `1024` filters\n",
    "\n",
    "- **Decoder (Expanding Path):**\n",
    "  - Consists of **4 upsampling blocks**\n",
    "  - Each block includes:\n",
    "    - A `2×2` transposed convolution to upsample and halve the number of filters\n",
    "    - A skip connection that concatenates the corresponding feature map from the encoder\n",
    "    - Two `3×3` convolutional layers with ReLU activation\n",
    "  - Filter sizes follow the reverse order:  \n",
    "    `1024 → 512 → 256 → 128 → 64`\n",
    "\n",
    "- **Output Layer:**\n",
    "  - A `1×1` convolution to reduce the channel dimension to the number of classes (**13**)\n",
    "  - Followed by a **softmax activation** to produce a probability distribution per pixel\n",
    "\n",
    "This architecture enables the model to segment objects at different scales and accurately preserve spatial information.\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Compilation and Training Setup\n",
    "\n",
    "- **Loss Function:**  \n",
    "  `SparseCategoricalCrossentropy` is used since the target masks contain integer class labels (not one-hot encoded).\n",
    "\n",
    "- **Optimizer:**  \n",
    "  `Adam` — a robust and widely used optimizer for deep learning, with a default learning rate.\n",
    "\n",
    "- **Metrics:**  \n",
    "  We track **pixel-wise accuracy** during training.  \n",
    "  More detailed metrics like **IoU** and **Dice coefficient** will be computed separately after training.\n",
    "\n",
    "- **Early Stopping:**  \n",
    "  To prevent overfitting, we use early stopping with `patience = 5`.  \n",
    "  This means training will stop if the validation loss does not improve for 5 consecutive epochs. The best-performing model weights are automatically restored.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebc4966-9e36-4b0d-b945-1582ea4b120d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                               │                           │                 │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │                 │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │                 │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │                 │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">845</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m1,792\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m36,928\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m147,584\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │       \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │       \u001b[38;5;34m9,438,208\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m2,097,664\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                               │                           │                 │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m524,544\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │                 │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m131,200\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │                 │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m147,584\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m32,832\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │                 │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m36,928\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m13\u001b[0m)      │             \u001b[38;5;34m845\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,032,525</span> (118.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,032,525\u001b[0m (118.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,032,525</span> (118.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,032,525\u001b[0m (118.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def build_unet(input_size=(256, 256, 3), num_classes=13):\n",
    "    \"\"\"Builds a U-Net model.\"\"\"\n",
    "    inputs = keras.Input(shape=input_size)\n",
    "    # Encoder: Downsampling through conv blocks and max pooling\n",
    "    c1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "    \n",
    "    c3 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D(pool_size=(2, 2))(c3)\n",
    "    \n",
    "    c4 = layers.Conv2D(512, kernel_size=3, activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, kernel_size=3, activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, kernel_size=3, activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, kernel_size=3, activation='relu', padding='same')(c5)\n",
    "    \n",
    "    # Decoder: Upsampling and skip connections\n",
    "    u6 = layers.Conv2DTranspose(512, kernel_size=2, strides=2, padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])  # skip connection from encoder c4\n",
    "    c6 = layers.Conv2D(512, kernel_size=3, activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, kernel_size=3, activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, kernel_size=2, strides=2, padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, activation='softmax')(c9)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b47be-2323-4972-8348-e3856b08cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the U-Net model and compile it\n",
    "num_classes = 13\n",
    "model = build_unet(input_size=(256, 256, 3), num_classes=num_classes)\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3fc05-e843-478f-a882-b392c68d8d31",
   "metadata": {},
   "source": [
    "<h3>b. Model Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18e4e9-0d74-4c62-a98c-68dd03fe5f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m498/808\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:05:21\u001b[0m 36s/step - accuracy: 0.8869 - loss: 1.2214"
     ]
    }
   ],
   "source": [
    "# Set up early stopping callback\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=8,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0afc58-c2fc-4371-a665-93e20bfc824e",
   "metadata": {},
   "source": [
    "<h2>III. Evaluation Metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89aa51-9491-4e0a-8f6c-85e31bd7de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred_probs, axis=-1)  # shape: (num_val, 256, 256)\n",
    "\n",
    "# Ensure the true labels (y_val) are proper type for comparison\n",
    "y_true = y_val  # already shape (num_val, 256, 256) as integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556a36c-05c1-4e7f-a6b1-2340b295f332",
   "metadata": {},
   "source": [
    "<h3>a. Pixel Accuracy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222040b5-6af7-46fa-9881-4f935775c158",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<p>Pixel Accuracy: the percentage of pixels (over the whole image set) whose predicted class matches the ground truth class. This is a global measure and was also tracked during training as the 'accuracy' metric.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb08a0-af4e-4592-9e04-756042801b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels = y_true.size\n",
    "correct_pixels = np.sum(y_pred == y_true)\n",
    "pixel_accuracy = correct_pixels / total_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e804a08-2e4d-4bda-9475-250f90132f2f",
   "metadata": {},
   "source": [
    "<h3>b. Intersection over Union (IoU)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb5e2f-f87f-442b-b9c4-d858c6840093",
   "metadata": {},
   "source": [
    "<p>Intersection over Union (IoU): for each class, IoU = (True Positive) / (True Positive + False Positive + False Negative), i.e., the area of overlap between the predicted mask and true mask divided by the area of their union. We will compute the IoU for each class and then take the average (Mean IoU) across all classes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbf12f-49ff-40a6-9b58-21e4883241f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 13\n",
    "iou_per_class = []\n",
    "for cls in range(num_classes):\n",
    "    # Compute intersection and union\n",
    "    pred_mask = (y_pred == cls)\n",
    "    true_mask = (y_true == cls)\n",
    "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
    "    union = np.logical_or(pred_mask, true_mask).sum()\n",
    "    if union == 0:\n",
    "        # If no pixel of this class is present in both pred and true, skip it (continue)\n",
    "        continue\n",
    "    iou = intersection / union\n",
    "    iou_per_class.append(iou)\n",
    "mean_iou = np.mean(iou_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f7c4e2-9b95-4a08-b124-a4a1e09d134f",
   "metadata": {},
   "source": [
    "<h3>c. Dice Coefficient</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9166ce8-72b2-4311-acd2-e110bb5bd21b",
   "metadata": {},
   "source": [
    "<p>Dice Coefficient: also known as F1 score for segmentation, Dice = 2 * (Precision * Recall) / (Precision + Recall) for each class, which can be computed as 2 * |Prediction ∩ Ground Truth| / (|Prediction| + |Ground Truth|). We will compute Dice per class and then average. Dice is closely related to IoU (Dice = 2*IoU/(IoU+1)) and emphasizes overlap.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8263b93-27a1-4db3-a43d-46b7f8141113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_per_class = []\n",
    "for cls in range(num_classes):\n",
    "    pred_mask = (y_pred == cls)\n",
    "    true_mask = (y_true == cls)\n",
    "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
    "    pred_area = pred_mask.sum()\n",
    "    true_area = true_mask.sum()\n",
    "    if true_area == 0 and pred_area == 0:\n",
    "        continue  # skip classes not present in either\n",
    "    # If only one is present and the other is not, intersection=0 will yield dice=0, which is fine.\n",
    "    dice = (2 * intersection) / (pred_area + true_area + 1e-8)\n",
    "    dice_per_class.append(dice)\n",
    "mean_dice = np.mean(dice_per_class)\n",
    "\n",
    "print(f\"Pixel Accuracy: {pixel_accuracy*100:.2f}%\")\n",
    "print(f\"Mean IoU: {mean_iou*100:.2f}%\")\n",
    "print(f\"Mean Dice Coefficient: {mean_dice*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e0a24-7020-46f8-b5ce-afadc7f2bc79",
   "metadata": {},
   "source": [
    "<h2>IV. Results Visualization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119dc67-0a7f-4b48-90d8-b8796a64bef1",
   "metadata": {},
   "source": [
    "<p>To get a better intuition of the model's performance, let's visualize some segmentation results. We'll take a few examples from the validation set and display:\n",
    "The original image.\n",
    "The ground truth mask (using a color overlay for different classes).\n",
    "The predicted mask from our model (using the same color scheme as ground truth for easy comparison).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa939a4-ee4b-4cb0-b089-d19e15bf041d",
   "metadata": {},
   "source": [
    "<p>We'll use a consistent color palette to color-code the 13 classes. For clarity, let's define a set of distinct colors for the classes. (These are arbitrary chosen colors for visualization; they may not match the exact colors used in the dataset's color mask, but serve to differentiate classes.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9d1c8-b685-4e9d-8170-60b4d6556a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a color for each class (in RGB)\n",
    "class_colors = [\n",
    "    (0, 0, 0),        # 0: background - black\n",
    "    (128, 64, 128),   # 1: e.g. abdominal wall - purple\n",
    "    (128, 128, 64),   # 2: liver - olive\n",
    "    (60, 180, 75),    # 3: GI tract - green\n",
    "    (255, 225, 25),   # 4: fat - yellow\n",
    "    (0, 130, 200),    # 5: grasper (instrument) - blue\n",
    "    (245, 130, 48),   # 6: connective tissue - orange\n",
    "    (220, 20, 60),    # 7: blood - crimson\n",
    "    (230, 190, 255),  # 8: cystic duct - lavender\n",
    "    (170, 110, 40),   # 9: electrocautery instrument - brown\n",
    "    (0, 0, 255),      # 10: gallbladder - bright blue\n",
    "    (128, 0, 0),      # 11: hepatic vein - maroon\n",
    "    (170, 255, 195)   # 12: liver ligament - mint\n",
    "]\n",
    "\n",
    "# Choose some sample indices from the validation set to visualize\n",
    "sample_indices = [0, 1, 2]  # (You can also choose random indices or specific ones)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    image = X_val[idx]\n",
    "    true_mask = y_val[idx]\n",
    "    pred_mask = y_pred[idx]\n",
    "    \n",
    "    # Construct color images for true mask and predicted mask\n",
    "    H, W = true_mask.shape\n",
    "    true_mask_color = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    pred_mask_color = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for cls, color in enumerate(class_colors):\n",
    "        true_mask_color[true_mask == cls] = color\n",
    "        pred_mask_color[pred_mask == cls] = color\n",
    "    \n",
    "    # Plot the results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(image)  # image is already normalized [0,1]\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(true_mask_color)\n",
    "    axes[1].set_title(\"Ground Truth Mask\")\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(pred_mask_color)\n",
    "    axes[2].set_title(\"Predicted Mask\")\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8471f-ba02-43fe-9ad1-c19025b6adcc",
   "metadata": {},
   "source": [
    "<h2>V. Deploy</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578ceb3-964a-4bc8-adf9-817ed899e622",
   "metadata": {},
   "source": [
    "<p>Finally, we save the trained model to disk so that it can be reloaded later for inference or further training without having to retrain from scratch. We'll save the model in Keras's HDF5 format:<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3bfc1-318c-45f5-8c16-d5df4a11c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cholecseg_unet_model.h5\")\n",
    "print(\"Model saved to disk.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
